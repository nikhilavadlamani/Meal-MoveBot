{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments\n",
    "import torch\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV data (use your dataset file here)\n",
    "meal_data = pd.read_csv('new_data.csv')\n",
    "\n",
    "# Prepare diverse question-answer pairs\n",
    "def prepare_data(df):\n",
    "    training_data = []\n",
    "    for _, row in df.iterrows():\n",
    "        # Extract relevant fields\n",
    "        recipe_name = row['TranslatedRecipeName']\n",
    "        ingredients = row['TranslatedIngredients']\n",
    "        instructions = row['TranslatedInstructions']\n",
    "        url = row['URL']\n",
    "        image_url = row['image-url']\n",
    "        cuisine = row['Cuisine']\n",
    "        time = row['TotalTimeInMins']\n",
    "\n",
    "        # Generate a variety of questions related to each meal\n",
    "        questions = [\n",
    "            f\"What can I cook with {ingredients}?\",\n",
    "            f\"Give me a recipe that includes {ingredients}.\",\n",
    "            f\"I want a {cuisine} recipe.\",\n",
    "            f\"Show me a recipe for {cuisine} cuisine.\",\n",
    "            f\"Show me a recipe that takes {time} minutes to cook.\",\n",
    "            f\"What can I make in under {time} minutes?\",\n",
    "            f\"How do I make {recipe_name}?\",\n",
    "            f\"Give me a {recipe_name} recipe with instructions.\",\n",
    "            f\"Where can I find more info about {recipe_name}?\",\n",
    "            f\"Show me an image of {recipe_name}.\",\n",
    "            f\"Give me a quick {cuisine} meal recipe.\",\n",
    "        ]\n",
    "\n",
    "        # Generate different answers based on question type\n",
    "        for question in questions:\n",
    "            if re.search(r'image of', question):\n",
    "                # Answer contains only the image URL\n",
    "                answer = f\"![Recipe Image]({image_url})\"\n",
    "            elif re.search(r'cuisine recipe|meal recipe', question):\n",
    "                # Answer contains the full recipe details\n",
    "                answer = (\n",
    "                    f\"**Recipe Name**: {recipe_name}\\n\\n\"\n",
    "                    \n",
    "                    f\"**Ingredients**: {ingredients}\\n\\n\"\n",
    "                    f\"**Instructions**: {instructions}\\n\\n\"\n",
    "                    f\"**URL**: {url}\\n\\n\"\n",
    "                    f\"![Recipe Image]({image_url})\"\n",
    "                )\n",
    "            elif re.search(r'cook with|without', question):\n",
    "                # Answer focuses on ingredients\n",
    "                answer = (\n",
    "                    f\"You can make **{recipe_name}** with the following ingredients:\\n\\n\"\n",
    "                    f\"**Ingredients**: {ingredients}\\n\\n\"\n",
    "                    f\"**Instructions**: {instructions}\\n\\n\"\n",
    "                    f\"![Recipe Image]({image_url})\"\n",
    "                )\n",
    "            else:\n",
    "                # Default to providing recipe instructions\n",
    "                answer = (\n",
    "                    f\"**Recipe Name**: {recipe_name}\\n\\n\"\n",
    "                    f\"**Ingredients**: {ingredients}\\n\\n\"\n",
    "                    f\"**Instructions**: {instructions}\\n\\n\"\n",
    "                    f\"**URL**: {url}\\n\\n\"\n",
    "                    f\"![Recipe Image]({image_url})\"\n",
    "                )\n",
    "            training_data.append({'question': question, 'answer': answer})\n",
    "    return training_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What can I cook with 1 tablespoon Red Chilli p...</td>\n",
       "      <td>You can make **Masala Karela Recipe** with the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Give me a recipe that includes 1 tablespoon Re...</td>\n",
       "      <td>**Recipe Name**: Masala Karela Recipe\\n\\n**Ing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I want a Indian recipe.</td>\n",
       "      <td>**Recipe Name**: Masala Karela Recipe\\n\\n**Ing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Show me a recipe for Indian cuisine.</td>\n",
       "      <td>**Recipe Name**: Masala Karela Recipe\\n\\n**Ing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Show me a recipe that takes 45 minutes to cook.</td>\n",
       "      <td>**Recipe Name**: Masala Karela Recipe\\n\\n**Ing...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  What can I cook with 1 tablespoon Red Chilli p...   \n",
       "1  Give me a recipe that includes 1 tablespoon Re...   \n",
       "2                            I want a Indian recipe.   \n",
       "3               Show me a recipe for Indian cuisine.   \n",
       "4    Show me a recipe that takes 45 minutes to cook.   \n",
       "\n",
       "                                              answer  \n",
       "0  You can make **Masala Karela Recipe** with the...  \n",
       "1  **Recipe Name**: Masala Karela Recipe\\n\\n**Ing...  \n",
       "2  **Recipe Name**: Masala Karela Recipe\\n\\n**Ing...  \n",
       "3  **Recipe Name**: Masala Karela Recipe\\n\\n**Ing...  \n",
       "4  **Recipe Name**: Masala Karela Recipe\\n\\n**Ing...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the data into a DataFrame \n",
    "train_df = pd.DataFrame(prepare_data(meal_data))\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eca77dfd54d94afa81a0e9ebf6bd624e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/65318 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2e74a48810e45df812b370c0361e828",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/devisris/Desktop/Project/chatbot/fine_tune.ipynb Cell 4\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/devisris/Desktop/Project/chatbot/fine_tune.ipynb#W6sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/devisris/Desktop/Project/chatbot/fine_tune.ipynb#W6sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m     model\u001b[39m=\u001b[39mmodel,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/devisris/Desktop/Project/chatbot/fine_tune.ipynb#W6sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m     args\u001b[39m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/devisris/Desktop/Project/chatbot/fine_tune.ipynb#W6sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m     tokenizer\u001b[39m=\u001b[39mtokenizer,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/devisris/Desktop/Project/chatbot/fine_tune.ipynb#W6sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/devisris/Desktop/Project/chatbot/fine_tune.ipynb#W6sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m \u001b[39m# Train the model\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/devisris/Desktop/Project/chatbot/fine_tune.ipynb#W6sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/transformers/trainer.py:1938\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1936\u001b[0m         hf_hub_utils\u001b[39m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1937\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1938\u001b[0m     \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   1939\u001b[0m         args\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m   1940\u001b[0m         resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[1;32m   1941\u001b[0m         trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[1;32m   1942\u001b[0m         ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[1;32m   1943\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/transformers/trainer.py:2279\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2276\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_handler\u001b[39m.\u001b[39mon_step_begin(args, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol)\n\u001b[1;32m   2278\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maccelerator\u001b[39m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 2279\u001b[0m     tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_step(model, inputs)\n\u001b[1;32m   2281\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   2282\u001b[0m     args\u001b[39m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2283\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2284\u001b[0m     \u001b[39mand\u001b[39;00m (torch\u001b[39m.\u001b[39misnan(tr_loss_step) \u001b[39mor\u001b[39;00m torch\u001b[39m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2285\u001b[0m ):\n\u001b[1;32m   2286\u001b[0m     \u001b[39m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2287\u001b[0m     tr_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m tr_loss \u001b[39m/\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mglobal_step \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/transformers/trainer.py:3318\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   3315\u001b[0m     \u001b[39mreturn\u001b[39;00m loss_mb\u001b[39m.\u001b[39mreduce_mean()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m   3317\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 3318\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_loss(model, inputs)\n\u001b[1;32m   3320\u001b[0m \u001b[39mdel\u001b[39;00m inputs\n\u001b[1;32m   3321\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   3322\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mtorch_empty_cache_steps \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   3323\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mglobal_step \u001b[39m%\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mtorch_empty_cache_steps \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m   3324\u001b[0m ):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/transformers/trainer.py:3363\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   3361\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   3362\u001b[0m     labels \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 3363\u001b[0m outputs \u001b[39m=\u001b[39m model(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minputs)\n\u001b[1;32m   3364\u001b[0m \u001b[39m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   3365\u001b[0m \u001b[39m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   3366\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mpast_index \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/transformers/models/gpt2/modeling_gpt2.py:1315\u001b[0m, in \u001b[0;36mGPT2LMHeadModel.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1307\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1308\u001b[0m \u001b[39mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1309\u001b[0m \u001b[39m    Labels for language modeling. Note that the labels **are shifted** inside the model, i.e. you can set\u001b[39;00m\n\u001b[1;32m   1310\u001b[0m \u001b[39m    `labels = input_ids` Indices are selected in `[-100, 0, ..., config.vocab_size]` All labels set to `-100`\u001b[39;00m\n\u001b[1;32m   1311\u001b[0m \u001b[39m    are ignored (masked), the loss is only computed for labels in `[0, ..., config.vocab_size]`\u001b[39;00m\n\u001b[1;32m   1312\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1313\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1315\u001b[0m transformer_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransformer(\n\u001b[1;32m   1316\u001b[0m     input_ids,\n\u001b[1;32m   1317\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m   1318\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   1319\u001b[0m     token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n\u001b[1;32m   1320\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[1;32m   1321\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m   1322\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m   1323\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m   1324\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_attention_mask,\n\u001b[1;32m   1325\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m   1326\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1327\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1328\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1329\u001b[0m )\n\u001b[1;32m   1330\u001b[0m hidden_states \u001b[39m=\u001b[39m transformer_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1332\u001b[0m \u001b[39m# Set device for model parallelism\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/transformers/models/gpt2/modeling_gpt2.py:1129\u001b[0m, in \u001b[0;36mGPT2Model.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1117\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m   1118\u001b[0m         block\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m,\n\u001b[1;32m   1119\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1126\u001b[0m         output_attentions,\n\u001b[1;32m   1127\u001b[0m     )\n\u001b[1;32m   1128\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1129\u001b[0m     outputs \u001b[39m=\u001b[39m block(\n\u001b[1;32m   1130\u001b[0m         hidden_states,\n\u001b[1;32m   1131\u001b[0m         layer_past\u001b[39m=\u001b[39;49mlayer_past,\n\u001b[1;32m   1132\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   1133\u001b[0m         head_mask\u001b[39m=\u001b[39;49mhead_mask[i],\n\u001b[1;32m   1134\u001b[0m         encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m   1135\u001b[0m         encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_attention_mask,\n\u001b[1;32m   1136\u001b[0m         use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m   1137\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1138\u001b[0m     )\n\u001b[1;32m   1140\u001b[0m hidden_states \u001b[39m=\u001b[39m outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1141\u001b[0m \u001b[39mif\u001b[39;00m use_cache \u001b[39mis\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/transformers/models/gpt2/modeling_gpt2.py:651\u001b[0m, in \u001b[0;36mGPT2Block.forward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    649\u001b[0m residual \u001b[39m=\u001b[39m hidden_states\n\u001b[1;32m    650\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mln_2(hidden_states)\n\u001b[0;32m--> 651\u001b[0m feed_forward_hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmlp(hidden_states)\n\u001b[1;32m    652\u001b[0m \u001b[39m# residual connection\u001b[39;00m\n\u001b[1;32m    653\u001b[0m hidden_states \u001b[39m=\u001b[39m residual \u001b[39m+\u001b[39m feed_forward_hidden_states\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/transformers/models/gpt2/modeling_gpt2.py:575\u001b[0m, in \u001b[0;36mGPT2MLP.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, hidden_states: Optional[Tuple[torch\u001b[39m.\u001b[39mFloatTensor]]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mFloatTensor:\n\u001b[1;32m    574\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mc_fc(hidden_states)\n\u001b[0;32m--> 575\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mact(hidden_states)\n\u001b[1;32m    576\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mc_proj(hidden_states)\n\u001b[1;32m    577\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(hidden_states)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "#convert data to Hugging Face dataset\n",
    "dataset = Dataset.from_pandas(train_df)\n",
    "\n",
    "# Load GPT-2 tokenizer and model\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "\n",
    "# Add a pad token to tokenizer\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Tokenize the dataset\n",
    "def tokenize_function(examples):\n",
    "    max_len = 2048  # Increased length for longer inputs\n",
    "    inputs = tokenizer(examples['question'], padding=\"max_length\", truncation=True, max_length=max_len)\n",
    "    outputs = tokenizer(examples['answer'], padding=\"max_length\", truncation=True, max_length=max_len)\n",
    "    inputs['labels'] = outputs['input_ids']\n",
    "    inputs['attention_mask'] = inputs['attention_mask']  # Include attention mask\n",
    "    return inputs\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "small_dataset = tokenized_dataset.select(range(100))  # Use the first 100 examples\n",
    "\n",
    "# Split the dataset into training and evaluation datasets\n",
    "train_test_split = small_dataset.train_test_split(test_size=0.1)\n",
    "train_dataset = train_test_split['train']\n",
    "eval_dataset = train_test_split['test']\n",
    "\n",
    "# Set training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",  \n",
    "    save_strategy=\"epoch\",       \n",
    "    load_best_model_at_end=True,  \n",
    "    metric_for_best_model=\"eval_loss\",    \n",
    "    greater_is_better=False,      \n",
    "    logging_dir=\"./logs\",         \n",
    "    logging_steps=100,            \n",
    "    save_steps=1000,              \n",
    "    save_total_limit=3,           \n",
    "    per_device_train_batch_size=2, \n",
    "    gradient_accumulation_steps=8, \n",
    "    learning_rate=2e-5,\n",
    "    num_train_epochs=5,  \n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What can I cook with potatoes?\n",
      "Response: What can I cook with potatoes?\n",
      "\n",
      "\n",
      "1 onion, chopped.\n",
      "\n",
      "4 cloves garlic, finely chopped\n",
      "... 1 large onion finely sliced. finely cut garlic. cut onions. thin. onion. mix with onion ( make onion mixture. the onion and garlic mixture to form a gravy. it is a good gravy of onions like the kadhi, the onions are also made in gravy, onion is also make a curry. stir fry onion paste, add onion oil and onions and fry. onions should heat, when onions will fry add onions, cook onions till onions cooked. add water to make salt. salt, to fry onions gravy to onions onions can also use gravy like kal dhi. when they are cooked, gravy gravy as curry is gravy and gravy is made, it that gravy can use curry paste. taste. serve, salt the gravy make gravy onions is it gravy curry onion in curry recipe. maddhi in recipe for gravy recipe, serve in kaddi. kkh kodhi to curry, curry to kh. curry krish. ( it make curry gravy or gravy for khen) kakk, kya, jin. fry the potatoes, fry them till they cook. as it curry mixture make and serve gravy in it. gravy kchy, in mak param, and gher. recipe, gravy pai, mix. or kar dh of gravy soup gravy, curry sou, make soup with gravy mix, ghee in the mix curry in its taste, ao., onion gravy will make it in mixture of onion, it it makes gravy so gravy gah dhar mam in onion soup, doe with it all the ghe, as gravy sare of gh soup. ghat, mare, or ghar. make ( in add to gravy it with to taste of curry and add it the curry ghan, then it will taste taste curry soup ghs, that kir ghes,,,. and that ghet, sind is in a taste to, of a- curry mou,. kj, o. of in and to. in. lak, is make in g h ky, a. like gravy by ghen gravy with ghot. to- s it gk. cook in onions : for las, this gravy use g ki, also git. also khes of to and s\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Give me a Chinese recipe.\n",
      "Response: Give me a Chinese recipe.\n",
      "\n",
      "In a large bowl, mix together the eggs and rice vinegar. Stir in the water. Add the egg mixture to the cooked rice and stir. The water will thicken the rice. I added it to it and it was so good. And then I chopped it. Now I put it in with the flour. stir it it then to stir the ground flour then add the powder. mix well it is to mix this with it a little. and then it will add it rice with powder and that is the. it with. rice of rice it can that be added or that the will mix it all together. this rice, rice rice recipe will also. make the ingredients. cooking.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: show me an image of a Masala Karela Recipe.\n",
      "Response: show me an image of a Masala Karela Recipe. You can use the image image to make your recipe. Print Recipe\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Show me a quick Italian meal recipe.\n",
      "Response: Show me a quick Italian meal recipe.\n",
      "\n",
      "Ingredients:\n",
      "- 1 cup cooked cilantro\n",
      " - 2 cups water\n",
      " – 1/4 cup cumin seeds\n",
      "*\n",
      "1 tsp cayenne powder\n",
      " 1 tsp garlic powder 1 1.1\n",
      " pumin powder - 1 pinch cary seeds of c c\n",
      " seeds -1 1 c. salt\n",
      "2 tbsp c oregano 1 tbsp finely chopped c parsley 1 onion - chopped\n",
      "juice 3 onions - finely sliced 3 onion(chopped) - cut 1 - ½ - 5 garlic cloves - minced 2 - 4 onion, chopped chopped salt 2 garlic - sauté 2 onions in cooking water for 1 hour. 3 1 = 2 hours 2 = 1 hours salt - for 4 to 8 onions, finely cut onions to 1 teaspoon in salt 1 salt-1 teaspoon 1 pepper 1 to 2 salt or salt to the onions (optional)\n",
      "(optional, if you are to make use with c, c and cy and add a dash c to add to taste. 1 : 1 is a lot for the taste, 3 the same. and so the salt and salt will give it a nice taste after cooking. to mix salt in onions or add salt salt with 2 teaspoon c o c salt. or to a pinch salt c of salt for added in some to it the spices. d or o onion can easily add this salt, like c y or c can as a curry or as can to curry with curry. if not can serve curry in gravy with salt of garlic. it taste the spicy curry powder c in this gravy. you can add the d with the cinnamon or the garlic and to get curry flavor, in onion in curry (or curry paste to be able to put it in the gravy can is it from c curry taste and the it is the c that will taste like curry curry) salt which is will add taste to spices as spices spice of curry, in garlic paste add onion as well as garlic in your mixture (you can not mix it with water). the paste is as in c for curry, salt then onion add onions and put in spices, salt also in it will make a taste of gravy spice spices like onion powder and onion salt is for salt curry recipe\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: I want a meal with rice and beans.\n",
      "Response: I want a meal with rice and beans. I want food with onions and potatoes.\n",
      "\n",
      "I cook rice with onion and potato and saute onions. You can also cook curry rice, I use a lot of onions with a saut. rice. And as for spices, the curry will be spicy. the rice is not cooked with spices.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Show me a vegan recipe.\n",
      "Response: Show me a vegan recipe.\n",
      "\n",
      "1/2 cup vegetable broth\n",
      ", (you can use any vegetable for your broth, or add the broth in small pieces if it is not hot. it will make it easier to make)\n",
      " 1/4 cup rice water\n",
      " ( or broth will add rice broth a very fast and thick rice and rice. rice is much better. you can omit the rice, rice rice soup is to slow cooker, make rice with rice flour. just add more rice in the soup rice will become very thin and smooth rice like rice can be served and add in soup. 1 cup water if you added rice to broth but rice it wont water. broth of rice\n",
      " to soup with the water, 1.1 cup soup to rice 4.4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Give me a recipe without peanuts.\n",
      "Response: Give me a recipe without peanuts. I think it is not as good as the banana curry.\n",
      "Ingredients:\n",
      "1 cup coconut milk,\n",
      "\n",
      "2 cups coconut oil, 1 cup chopped nuts, or to taste\n",
      "\n",
      "\n",
      "Query: Show me a recipe that takes 30 minutes to cook.\n",
      "Response: Show me a recipe that takes 30 minutes to cook.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Save the fine-tuned model and tokenizer\n",
    "model.save_pretrained(\"./fine_tuned_meal_plan_model\")\n",
    "tokenizer.save_pretrained(\"./fine_tuned_meal_plan_model\")\n",
    "\n",
    "# Detect the device (CUDA, MPS for Apple, or CPU)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "model = model.to(device)\n",
    "\n",
    "def test_model(model, tokenizer):\n",
    "    \n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "    test_queries = [\n",
    "        \"What can I cook with potatoes?\",\n",
    "        \"Give me a Chinese recipe.\",\n",
    "        \"show me an image of a Masala Karela Recipe.\",\n",
    "        \"Show me a quick Italian meal recipe.\",\n",
    "        \"I want a meal with rice and beans.\",\n",
    "        \"Show me a vegan recipe.\",\n",
    "        \"Give me a recipe without peanuts.\",\n",
    "        \"Show me a recipe that takes 30 minutes to cook.\"\n",
    "    ]\n",
    "    \n",
    "    for query in test_queries:\n",
    "        # Move input data to the model's device (CUDA, MPS, or CPU)\n",
    "        inputs = tokenizer(query, return_tensors='pt', padding=True, truncation=True)\n",
    "        inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "        \n",
    "        outputs = model.generate(\n",
    "            inputs['input_ids'], \n",
    "            attention_mask=inputs['attention_mask'], \n",
    "            max_length=1024, \n",
    "            do_sample=True, \n",
    "            top_k=50,  \n",
    "            top_p=0.95,  \n",
    "            temperature=0.7,  \n",
    "            no_repeat_ngram_size=2,  # To avoid repetition\n",
    "            #pad_token_id=tokenizer.eos_token_id  # Set pad token explicitly\n",
    "        )\n",
    "        response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        print(f\"Query: {query}\")\n",
    "        print(f\"Response: {response}\\n\")\n",
    "        \n",
    "# Run the test_model function with the fine-tuned model\n",
    "test_model(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
